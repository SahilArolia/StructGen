{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StructGAN Data Exploration\n",
    "\n",
    "This notebook explores the StructGAN dataset structure and visualizes sample data.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Imports\n",
    "2. Explore Dataset Structure\n",
    "3. Visualize Sample Images\n",
    "4. Analyze Data Distribution\n",
    "5. Preprocessing Pipeline Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "# Project imports\n",
    "from src.data_preprocessing.dataset import StructGANDataset, visualize_sample\n",
    "from src.utils.visualization import tensor_to_image\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check StructGAN repository\n",
    "structgan_path = project_root / \"StructGAN_v1\"\n",
    "datasets_path = structgan_path / \"0_datasets\"\n",
    "\n",
    "print(f\"StructGAN repository exists: {structgan_path.exists()}\")\n",
    "print(f\"Datasets folder exists: {datasets_path.exists()}\")\n",
    "\n",
    "if datasets_path.exists():\n",
    "    print(\"\\nAvailable dataset groups:\")\n",
    "    for item in sorted(datasets_path.iterdir()):\n",
    "        if item.is_dir() and \"Group\" in item.name:\n",
    "            n_images = len(list(item.glob(\"*.png\"))) + len(list(item.glob(\"*.jpg\")))\n",
    "            print(f\"  {item.name}: {n_images} images\")\n",
    "else:\n",
    "    print(\"\\nPlease run setup.sh first to clone the StructGAN repository.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in a dataset group\n",
    "dataset_name = \"Group7-H2\"  # Change this to explore different groups\n",
    "dataset_dir = datasets_path / dataset_name\n",
    "\n",
    "if dataset_dir.exists():\n",
    "    image_files = sorted(list(dataset_dir.glob(\"*.png\")) + list(dataset_dir.glob(\"*.jpg\")))\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    print(f\"Total images: {len(image_files)}\")\n",
    "    print(f\"\\nFirst 5 files:\")\n",
    "    for f in image_files[:5]:\n",
    "        print(f\"  {f.name}\")\n",
    "else:\n",
    "    print(f\"Dataset {dataset_name} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_paired_image(image_path):\n",
    "    \"\"\"Display a paired image (input|target side by side).\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    w = img_np.shape[1]\n",
    "    h = img_np.shape[0]\n",
    "    \n",
    "    # Split into input and target\n",
    "    input_img = img_np[:, :w//2, :]\n",
    "    target_img = img_np[:, w//2:, :]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(input_img)\n",
    "    axes[0].set_title('Input: Architectural Plan')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(target_img)\n",
    "    axes[1].set_title('Target: Structural Layout')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = cv2.addWeighted(input_img, 0.5, target_img, 0.5, 0)\n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title('Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(Path(image_path).name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return input_img, target_img\n",
    "\n",
    "# Show a sample image\n",
    "if 'image_files' in dir() and len(image_files) > 0:\n",
    "    input_img, target_img = show_paired_image(image_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display multiple samples\n",
    "if 'image_files' in dir() and len(image_files) > 0:\n",
    "    n_samples = min(6, len(image_files))\n",
    "    fig, axes = plt.subplots(n_samples, 2, figsize=(10, 4 * n_samples))\n",
    "    \n",
    "    for i, img_path in enumerate(image_files[:n_samples]):\n",
    "        img = Image.open(img_path)\n",
    "        img_np = np.array(img)\n",
    "        w = img_np.shape[1]\n",
    "        \n",
    "        input_img = img_np[:, :w//2, :]\n",
    "        target_img = img_np[:, w//2:, :]\n",
    "        \n",
    "        axes[i, 0].imshow(input_img)\n",
    "        axes[i, 0].set_title(f'Input {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(target_img)\n",
    "        axes[i, 1].set_title(f'Target {i+1}')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image_path):\n",
    "    \"\"\"Analyze a single paired image.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    w = img_np.shape[1]\n",
    "    target_img = img_np[:, w//2:, :]\n",
    "    \n",
    "    # Count structural element pixels\n",
    "    # Assuming red = shear walls, blue = columns\n",
    "    red_mask = (target_img[:,:,0] > 200) & (target_img[:,:,1] < 100) & (target_img[:,:,2] < 100)\n",
    "    blue_mask = (target_img[:,:,2] > 200) & (target_img[:,:,0] < 100) & (target_img[:,:,1] < 100)\n",
    "    \n",
    "    total_pixels = target_img.shape[0] * target_img.shape[1]\n",
    "    \n",
    "    return {\n",
    "        'width': w // 2,\n",
    "        'height': img_np.shape[0],\n",
    "        'wall_ratio': np.sum(red_mask) / total_pixels,\n",
    "        'column_ratio': np.sum(blue_mask) / total_pixels\n",
    "    }\n",
    "\n",
    "# Analyze all images\n",
    "if 'image_files' in dir() and len(image_files) > 0:\n",
    "    stats = [analyze_image(f) for f in image_files]\n",
    "    \n",
    "    print(f\"Dataset Statistics ({len(stats)} images):\")\n",
    "    print(f\"Image size: {stats[0]['width']} x {stats[0]['height']}\")\n",
    "    print(f\"\\nShear Wall Ratio:\")\n",
    "    print(f\"  Mean: {np.mean([s['wall_ratio'] for s in stats]):.4f}\")\n",
    "    print(f\"  Std:  {np.std([s['wall_ratio'] for s in stats]):.4f}\")\n",
    "    print(f\"  Min:  {np.min([s['wall_ratio'] for s in stats]):.4f}\")\n",
    "    print(f\"  Max:  {np.max([s['wall_ratio'] for s in stats]):.4f}\")\n",
    "    print(f\"\\nColumn Ratio:\")\n",
    "    print(f\"  Mean: {np.mean([s['column_ratio'] for s in stats]):.4f}\")\n",
    "    print(f\"  Std:  {np.std([s['column_ratio'] for s in stats]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions\n",
    "if 'stats' in dir():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].hist([s['wall_ratio'] for s in stats], bins=20, edgecolor='black')\n",
    "    axes[0].set_title('Shear Wall Ratio Distribution')\n",
    "    axes[0].set_xlabel('Wall Ratio')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    \n",
    "    axes[1].hist([s['column_ratio'] for s in stats], bins=20, edgecolor='black')\n",
    "    axes[1].set_title('Column Ratio Distribution')\n",
    "    axes[1].set_xlabel('Column Ratio')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our custom dataset class\n",
    "if 'dataset_dir' in dir() and dataset_dir.exists():\n",
    "    dataset = StructGANDataset(\n",
    "        root_dir=str(dataset_dir),\n",
    "        split=\"train\",\n",
    "        image_size=256,\n",
    "        paired_format=\"side_by_side\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset size: {len(dataset)}\")\n",
    "    \n",
    "    # Get a sample\n",
    "    input_tensor, target_tensor = dataset[0]\n",
    "    print(f\"Input shape: {input_tensor.shape}\")\n",
    "    print(f\"Target shape: {target_tensor.shape}\")\n",
    "    print(f\"Input range: [{input_tensor.min():.2f}, {input_tensor.max():.2f}]\")\n",
    "    print(f\"Target range: [{target_tensor.min():.2f}, {target_tensor.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tensor samples\n",
    "if 'dataset' in dir():\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    for i in range(4):\n",
    "        input_t, target_t = dataset[i]\n",
    "        \n",
    "        # Convert from [-1, 1] to [0, 1]\n",
    "        input_img = ((input_t + 1) / 2).permute(1, 2, 0).numpy()\n",
    "        target_img = ((target_t + 1) / 2).permute(1, 2, 0).numpy()\n",
    "        \n",
    "        axes[0, i].imshow(input_img)\n",
    "        axes[0, i].set_title(f'Input {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        axes[1, i].imshow(target_img)\n",
    "        axes[1, i].set_title(f'Target {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Color Analysis of Structural Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_colors(image_path):\n",
    "    \"\"\"Analyze the color distribution in target image.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    w = img_np.shape[1]\n",
    "    target = img_np[:, w//2:, :]\n",
    "    \n",
    "    # Get unique colors\n",
    "    pixels = target.reshape(-1, 3)\n",
    "    unique_colors = np.unique(pixels, axis=0)\n",
    "    \n",
    "    # Count each color\n",
    "    color_counts = {}\n",
    "    for color in unique_colors:\n",
    "        mask = np.all(pixels == color, axis=1)\n",
    "        count = np.sum(mask)\n",
    "        color_counts[tuple(color)] = count\n",
    "    \n",
    "    return color_counts\n",
    "\n",
    "# Analyze colors in first image\n",
    "if 'image_files' in dir() and len(image_files) > 0:\n",
    "    colors = analyze_colors(image_files[0])\n",
    "    \n",
    "    print(\"Top 10 colors in structural layout:\")\n",
    "    sorted_colors = sorted(colors.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(sorted_colors), figsize=(2*len(sorted_colors), 2))\n",
    "    \n",
    "    for i, (color, count) in enumerate(sorted_colors):\n",
    "        patch = np.ones((50, 50, 3), dtype=np.uint8) * np.array(color, dtype=np.uint8)\n",
    "        axes[i].imshow(patch)\n",
    "        axes[i].set_title(f'{count} px\\n{color}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key observations about the dataset:\n",
    "\n",
    "1. **Format**: Images are paired side-by-side (input|target)\n",
    "2. **Size**: Typically 512x256 combined (256x256 each)\n",
    "3. **Color Coding**:\n",
    "   - Input: Room colors, black walls, door/window markers\n",
    "   - Target: Red = shear walls, Blue = columns, White = background\n",
    "4. **Distribution**: Wall coverage varies, columns are sparse\n",
    "\n",
    "Next steps:\n",
    "- Run baseline training: `python src/training/train_baseline.py`\n",
    "- Monitor with TensorBoard: `tensorboard --logdir models/checkpoints`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
